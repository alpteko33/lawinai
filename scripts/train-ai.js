#!/usr/bin/env node

/**
 * AI EÄŸitim Scripti
 * 
 * Bu script, AI Training Panel'den dÄ±ÅŸa aktarÄ±lan verileri kullanarak
 * yapay zeka modelini eÄŸitmek iÃ§in gerekli dosyalarÄ± hazÄ±rlar.
 * 
 * KullanÄ±m:
 * node scripts/train-ai.js [options]
 * 
 * SeÃ§enekler:
 * --input: EÄŸitim verilerinin bulunduÄŸu klasÃ¶r (varsayÄ±lan: ./)
 * --output: Ã‡Ä±ktÄ± klasÃ¶rÃ¼ (varsayÄ±lan: ./training-output)
 * --format: Ã‡Ä±ktÄ± formatÄ± (json, csv, embeddings) (varsayÄ±lan: all)
 */

const fs = require('fs');
const path = require('path');

// Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± parse et
const args = process.argv.slice(2);
const options = {
  input: './',
  output: './training-output',
  format: 'all'
};

for (let i = 0; i < args.length; i++) {
  if (args[i] === '--input' && args[i + 1]) {
    options.input = args[i + 1];
    i++;
  } else if (args[i] === '--output' && args[i + 1]) {
    options.output = args[i + 1];
    i++;
  } else if (args[i] === '--format' && args[i + 1]) {
    options.format = args[i + 1];
    i++;
  }
}

console.log('ğŸ¤– AI EÄŸitim Scripti BaÅŸlatÄ±lÄ±yor...');
console.log('ğŸ“ GiriÅŸ klasÃ¶rÃ¼:', options.input);
console.log('ğŸ“ Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼:', options.output);
console.log('ğŸ“„ Format:', options.format);

// Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼nÃ¼ oluÅŸtur
if (!fs.existsSync(options.output)) {
  fs.mkdirSync(options.output, { recursive: true });
  console.log('âœ… Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼ oluÅŸturuldu:', options.output);
}

// EÄŸitim verilerini yÃ¼kle
function loadTrainingData() {
  const trainingDataPath = path.join(options.input, 'training-data.json');
  
  if (!fs.existsSync(trainingDataPath)) {
    console.error('âŒ training-data.json dosyasÄ± bulunamadÄ±:', trainingDataPath);
    console.log('ğŸ’¡ AI Training Panel\'den verileri dÄ±ÅŸa aktarÄ±n');
    process.exit(1);
  }
  
  try {
    const data = fs.readFileSync(trainingDataPath, 'utf8');
    const trainingData = JSON.parse(data);
    console.log('âœ… EÄŸitim verileri yÃ¼klendi');
    console.log(`   ğŸ“Š ${trainingData.metadata.totalDocuments} dokÃ¼man`);
    console.log(`   ğŸ“Š ${trainingData.metadata.totalChunks} parÃ§a`);
    console.log(`   ğŸ“Š ${trainingData.metadata.totalEmbeddings} embedding`);
    return trainingData;
  } catch (error) {
    console.error('âŒ EÄŸitim verileri yÃ¼klenemedi:', error.message);
    process.exit(1);
  }
}

// Verileri analiz et
function analyzeData(trainingData) {
  console.log('\nğŸ“ˆ Veri Analizi:');
  
  const { trainingData: chunks } = trainingData;
  
  // DokÃ¼man tÃ¼rlerine gÃ¶re analiz
  const documentTypes = {};
  const documentNames = {};
  const processingTypes = {};
  
  chunks.forEach(chunk => {
    const type = chunk.metadata.documentType;
    const name = chunk.metadata.documentName;
    const processingType = chunk.metadata.processingType || 'text';
    
    documentTypes[type] = (documentTypes[type] || 0) + 1;
    documentNames[name] = (documentNames[name] || 0) + 1;
    processingTypes[processingType] = (processingTypes[processingType] || 0) + 1;
  });
  
  console.log('   ğŸ“„ DokÃ¼man TÃ¼rleri:');
  Object.entries(documentTypes).forEach(([type, count]) => {
    console.log(`      ${type.toUpperCase()}: ${count} parÃ§a`);
  });
  
  console.log('   ğŸ“„ DokÃ¼manlar:');
  Object.entries(documentNames).forEach(([name, count]) => {
    console.log(`      ${name}: ${count} parÃ§a`);
  });
  
  console.log('   ğŸ”§ Ä°ÅŸleme TÃ¼rleri:');
  Object.entries(processingTypes).forEach(([type, count]) => {
    console.log(`      ${type}: ${count} parÃ§a`);
  });
  
  // Embedding boyutu
  if (chunks.length > 0 && chunks[0].embedding) {
    console.log(`   ğŸ”¢ Embedding Boyutu: ${chunks[0].embedding.length}`);
  }
  
  return { documentTypes, documentNames, processingTypes };
}

// EÄŸitim verilerini hazÄ±rla
function prepareTrainingData(trainingData) {
  console.log('\nğŸ”§ EÄŸitim Verileri HazÄ±rlanÄ±yor...');
  
  const { trainingData: chunks } = trainingData;
  
  // FarklÄ± formatlarda veri hazÄ±rla
  const formats = {
    json: prepareJSONFormat(trainingData),
    csv: prepareCSVFormat(chunks),
    embeddings: prepareEmbeddingsFormat(chunks),
    metadata: prepareMetadataFormat(trainingData.metadata)
  };
  
  return formats;
}

// JSON formatÄ± hazÄ±rla
function prepareJSONFormat(trainingData) {
  return {
    filename: 'training-data-processed.json',
    content: JSON.stringify(trainingData, null, 2)
  };
}

// CSV formatÄ± hazÄ±rla
function prepareCSVFormat(chunks) {
  const headers = ['id', 'content', 'document_name', 'document_type', 'chunk_index', 'total_chunks', 'chunk_length'];
  const rows = chunks.map(chunk => [
    chunk.id,
    `"${chunk.content.replace(/"/g, '""')}"`,
    chunk.metadata.documentName,
    chunk.metadata.documentType,
    chunk.metadata.chunkIndex,
    chunk.metadata.totalChunks,
    chunk.metadata.chunkLength
  ]);
  
  const csvContent = [headers.join(','), ...rows.map(row => row.join(','))].join('\n');
  
  return {
    filename: 'training-data.csv',
    content: csvContent
  };
}

// Embedding formatÄ± hazÄ±rla
function prepareEmbeddingsFormat(chunks) {
  const embeddings = chunks.map(chunk => chunk.embedding);
  const metadata = {
    totalEmbeddings: embeddings.length,
    embeddingDimension: embeddings[0]?.length || 0,
    exportDate: new Date().toISOString()
  };
  
  return {
    filename: 'embeddings.json',
    content: JSON.stringify({ metadata, embeddings }, null, 2)
  };
}

// Metadata formatÄ± hazÄ±rla
function prepareMetadataFormat(metadata) {
  return {
    filename: 'metadata.json',
    content: JSON.stringify(metadata, null, 2)
  };
}

// DosyalarÄ± kaydet
function saveFiles(formats) {
  console.log('\nğŸ’¾ Dosyalar Kaydediliyor...');
  
  const formatsToSave = options.format === 'all' 
    ? Object.keys(formats) 
    : [options.format];
  
  formatsToSave.forEach(format => {
    if (formats[format]) {
      const filePath = path.join(options.output, formats[format].filename);
      fs.writeFileSync(filePath, formats[format].content);
      console.log(`   âœ… ${formats[format].filename} kaydedildi`);
    }
  });
}

// EÄŸitim konfigÃ¼rasyonu oluÅŸtur
function createTrainingConfig(trainingData) {
  console.log('\nâš™ï¸ EÄŸitim KonfigÃ¼rasyonu OluÅŸturuluyor...');
  
  const config = {
    model: {
      name: 'lawinai-legal-assistant',
      version: '1.0.0',
      description: 'TÃ¼rk hukuk sistemi iÃ§in eÄŸitilmiÅŸ AI asistan',
      baseModel: process.env.VITE_GEMINI_MODEL || 'gemini-2.5-pro'
    },
    training: {
      totalDocuments: trainingData.metadata.totalDocuments,
      totalChunks: trainingData.metadata.totalChunks,
      totalEmbeddings: trainingData.metadata.totalEmbeddings,
      embeddingDimension: trainingData.trainingData[0]?.embedding?.length || 0,
      chunkSize: 1000,
      embeddingModel: process.env.VITE_GEMINI_EMBEDDING_MODEL || 'text-embedding-004'
    },
    data: {
      inputFiles: ['training-data-processed.json', 'embeddings.json'],
      outputFormat: 'json',
      validationSplit: 0.2,
      testSplit: 0.1
    },
    hyperparameters: {
      learningRate: 0.001,
      batchSize: 32,
      epochs: 100,
      temperature: 0.3,
      maxTokens: 4096
    },
    metadata: {
      createdAt: new Date().toISOString(),
      author: 'LawInAI Team',
      license: 'MIT',
      domain: 'Turkish Legal System'
    }
  };
  
  const configPath = path.join(options.output, 'training-config.json');
  fs.writeFileSync(configPath, JSON.stringify(config, null, 2));
  console.log('   âœ… training-config.json oluÅŸturuldu');
  
  return config;
}

// README dosyasÄ± oluÅŸtur
function createREADME(trainingData, config) {
  console.log('\nğŸ“ README DosyasÄ± OluÅŸturuluyor...');
  
  const readme = `# LawInAI EÄŸitim Verileri

Bu klasÃ¶r, LawInAI yapay zeka modelinin eÄŸitimi iÃ§in hazÄ±rlanmÄ±ÅŸ verileri iÃ§erir.

## ğŸ“Š Veri Ä°statistikleri

- **Toplam DokÃ¼man**: ${trainingData.metadata.totalDocuments}
- **Toplam ParÃ§a**: ${trainingData.metadata.totalChunks}
- **Toplam Embedding**: ${trainingData.metadata.totalEmbeddings}
- **Embedding Boyutu**: ${config.training.embeddingDimension}
- **OluÅŸturulma Tarihi**: ${new Date().toLocaleDateString('tr-TR')}

## ğŸ“ Dosyalar

- \`training-data-processed.json\` - Ä°ÅŸlenmiÅŸ eÄŸitim verileri
- \`training-data.csv\` - CSV formatÄ±nda veriler
- \`embeddings.json\` - Embedding vektÃ¶rleri
- \`metadata.json\` - Veri metadata'sÄ±
- \`training-config.json\` - EÄŸitim konfigÃ¼rasyonu

## ğŸš€ KullanÄ±m

Bu verileri kullanarak AI modelini eÄŸitmek iÃ§in:

1. EÄŸitim framework'Ã¼nÃ¼zÃ¼ seÃ§in (TensorFlow, PyTorch, vb.)
2. \`training-config.json\` dosyasÄ±ndaki parametreleri kullanÄ±n
3. \`embeddings.json\` dosyasÄ±ndan embedding'leri yÃ¼kleyin
4. Model eÄŸitimini baÅŸlatÄ±n

## âš ï¸ Ã–nemli Notlar

- Bu veriler TÃ¼rk hukuk sistemi iÃ§in Ã¶zelleÅŸtirilmiÅŸtir
- Veriler gÃ¼ncel tutulmalÄ±dÄ±r
- EÄŸitim sonrasÄ± model performansÄ± test edilmelidir

## ğŸ“ Destek

Sorunlar iÃ§in LawInAI geliÅŸtirme ekibiyle iletiÅŸime geÃ§in.
`;

  const readmePath = path.join(options.output, 'README.md');
  fs.writeFileSync(readmePath, readme);
  console.log('   âœ… README.md oluÅŸturuldu');
}

// Ana fonksiyon
function main() {
  try {
    // EÄŸitim verilerini yÃ¼kle
    const trainingData = loadTrainingData();
    
    // Verileri analiz et
    analyzeData(trainingData);
    
    // EÄŸitim verilerini hazÄ±rla
    const formats = prepareTrainingData(trainingData);
    
    // DosyalarÄ± kaydet
    saveFiles(formats);
    
    // EÄŸitim konfigÃ¼rasyonu oluÅŸtur
    const config = createTrainingConfig(trainingData);
    
    // README dosyasÄ± oluÅŸtur
    createREADME(trainingData, config);
    
    console.log('\nğŸ‰ AI EÄŸitim Verileri BaÅŸarÄ±yla HazÄ±rlandÄ±!');
    console.log(`ğŸ“ Ã‡Ä±kÄ±ÅŸ klasÃ¶rÃ¼: ${options.output}`);
    console.log('\nğŸ“‹ Sonraki AdÄ±mlar:');
    console.log('1. EÄŸitim framework\'Ã¼nÃ¼zÃ¼ seÃ§in');
    console.log('2. training-config.json dosyasÄ±nÄ± inceleyin');
    console.log('3. Model eÄŸitimini baÅŸlatÄ±n');
    console.log('4. Model performansÄ±nÄ± test edin');
    
  } catch (error) {
    console.error('âŒ Hata:', error.message);
    process.exit(1);
  }
}

// Scripti Ã§alÄ±ÅŸtÄ±r
if (require.main === module) {
  main();
}

module.exports = {
  loadTrainingData,
  analyzeData,
  prepareTrainingData,
  createTrainingConfig
}; 